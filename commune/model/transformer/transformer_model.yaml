
model: gpt125m
tokenizer: null
epoch_length: 10
save: true # save on epoch 
device: null
epoch_length: 100
max_gpu_ratio: 0.8
finetune: 1
optimizer:
  lr: 1.0e-05
  module: torch.optim.Adam
load_in_8bit: False
stats: {}
max_gpu_ratio: 0.8
model_inflation_ratio: 1.4
output_length: 4
max_sequence_length: 256
tag: null
test: true
reserve_gpus: null
load: false
device_map: null
max_memory: null
verbose: true


