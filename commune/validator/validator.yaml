
models: model.
network: global
update: True
tokenizer: gpt2
train: False
batch_size: 32
sequence_length: 256
dataset: dataset.bittensor
stats: {}
metric:  null
stats: {}
threshold: 4.0
max_stats_history: 100
namespace_update_interval: 100
alpha: 0.1
ma_keys: ['metric', 'weights']
ratio: 1.0
topk: 512 
load: True
save: True
new_loop_per_forward: True
hidden_size : 512
