
models: model.
network: global
update: True
tokenizer: gpt2
train: False
batch_size: 8
sequence_length: 256
dataset: dataset.bittensor
metric:  null
stats: {}
threshold: 4.0
max_stats_history: 100
alpha: 0.1
ma_keys: ['metric', 'weights']
selection_ratio: 1.0
topk: 512 
load: False
new_loop_per_forward: True
hidden_size : 512
